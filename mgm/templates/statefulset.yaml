apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "mgm.fullname" . }}
  labels:
    {{- include "mgm.labels" . | nindent 4 }}
spec:
  serviceName: {{ include "mgm.fullname" . }}
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "mgm.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "mgm.selectorLabels" . | nindent 8 }}
    spec:
      containers:
        - name: eos-mgm
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ["/bin/sh", "-c"]
          args: ["/usr/bin/xrootd -n mgm -c /etc/xrd.cf.mgm -l /var/log/eos/xrdlog.mgm -Rdaemon"]   # TODO: Check which xrootd binary should be used
          ports:
            - name: xrootd-mgm
              containerPort: 1094
              protocol: TCP
            - name: xrootd-sync
              containerPort: 1096
              protocol: TCP
            - name: xrootd-http
              containerPort: 8000
              protocol: TCP
            - name: fusex
              containerPort: 1100
              protocol: TCP
          env:
            # leave it aside until the qdb chart is done
            # - name: EOS_QUARKDB_HOSTPORT
            #   value: "eos-qdb.eos-qdb.%%%NAMESPACE%%%.svc.cluster.local:7777"
            # Inspiration from cockroachdb, in case we need it:
            # - name: STATEFULSET_NAME
            #   value: {{ template "mgm.fullname" . }}
            # - name: STATEFULSET_FQDN
            #   value: {{ template "mgm.fullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.clusterDomain }}
            ### work around current Kubernetes setup issues. This should *NOT* be enabled in production
          envFrom:
            - configMapRef:
                name: {{ include "mgm.fullname" . }}-cfgmap-sysconfig-eos
          securityContext:
            privileged: true
            allowPrivilegeEscalation: true
            capabilities:
              add: ["SYS_PTRACE"]
          # startupProbe when deployed on kubectl >= 1.16
          # exec:
          #   command:
          #   - /volumes/configmap/configure.sh
          # livenessProbe:
          #   httpGet:
          #     path: /
          #     port: http
          # readinessProbe:
          #   httpGet:
          #     path: /
          #     port: http
          {{- include "mgm.startupProbe" . | nindent 10 }}
          volumeMounts:
            - name: mgm-cfgmap-xrd-cf-mgm
              mountPath: /etc/xrd.cf.mgm
              subPath: xrd.cf.mgm
            - name: mgm-data
              mountPath: /var/eos
            - name: mgm-logs
              mountPath: /var/log/eos
      initContainers:
        - name: eos-mgm-init0-logfolder-create
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ["/bin/sh", "-c"]
          args: ["for fld in mgm tx; do mkdir /var/log/eos/$fld; done && chown -R daemon:daemon /var/log/eos"]
          volumeMounts:
            - name: mgm-logs
              mountPath: /var/log/eos
        - name: eos-mgm-init1-nsqueue-create
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          command: ["/bin/sh", "-c"]
          args: ["for fld in ns-queue; do mkdir /var/eos/$fld; done && chown -R daemon:daemon /var/eos"]
          volumeMounts:
            - name: mgm-data
              mountPath: /var/eos
        - name: eos-mgm-init2-mgm-init
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          envFrom:
            - configMapRef:
                name: {{ include "mgm.fullname" . }}-cfgmap-sysconfig-eos
          securityContext:
            privileged: true
            allowPrivilegeEscalation: true
            capabilities:
              add: ["SYS_PTRACE"]
          command: ["/bin/bash", "/root/mgm_init.sh"]
          volumeMounts:
            - name: mgm-cfgmap-xrd-cf-mgm
              mountPath: /etc/xrd.cf.mgm
              subPath: xrd.cf.mgm
            - name: mgm-data
              mountPath: /var/eos
            - name: mgm-logs
              mountPath: /var/log/eos
            - name: mgm-cfgmap-mgm-init
              mountPath: /root/mgm_init.sh
              subPath: mgm_init.sh
      volumes:
        # @note having an `emptyDir: {}` mounted at `mountPath: /some/path` will "mask/erase"
        # everything pre-existing in the container located at /some/path.
        # i.e. the eos-server puts by default some necessary files and folder in /var/eos/;
        # mounting an emptyDir there, will thus mask/erase those files, leaving indeed just an empty directory!
        # Bitten with /var/eos/qos* with eos v4.8.20+, QoS support enabled, and default mgmofs.qos* paths...
        - name: mgm-cfgmap-xrd-cf-mgm
          configMap:
            name: {{ include "mgm.fullname" . }}-cfgmap-xrd-cf-mgm
            defaultMode: 0755
        - name: mgm-cfgmap-mgm-init
          configMap:
            name: {{ include "mgm.fullname" . }}-cfgmap-mgm-init
            defaultMode: 0755
        - name: mgm-data
          emptyDir: {}
          # hostPath:
            # path: /var/k8s/volumes/{{ include "mgm.name" . }}/mgm-data
            # type: DirectoryOrCreate
        - name: mgm-logs
          emptyDir: {}
          # hostPath:
            # path: /var/k8s/volumes/{{ include "mgm.name" . }}-mgm-logs
            # type: DirectoryOrCreate
